Package: tinyllama
Version: 1.2.3
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: python3-venv, python3-pip, curl, git, tlweb-marketplace (>= 0.9.1)
Suggests: tinyllama-mdns
Filename: pool/testing/main/tinyllama_1.2.3_amd64.deb
Size: 1300536
MD5sum: da82d61aa8007af16fb249a222f7af8c
SHA1: 370f6e471ba87ad2b788938238df4cebc49205b3
SHA256: 1c9a37e049906756f3eacdfe642c3f0d51811adf0135e56152d9aabf4f878ff2
Section: utils
Priority: optional
Description: Official Tiny Llama webserver by InsightReactions

Package: tinyllama-mdns
Version: 1.0.1
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: avahi-daemon
Recommends: tinyllama
Filename: pool/testing/main/tinyllama-mdns_1.0.1_amd64.deb
Size: 1106
MD5sum: 473c50f29d762a4b292ecaa2d583505e
SHA1: b3ee7cb7b9609407848c6042b61d9d998d6fc5a2
SHA256: eb5de131bb4bca620cdb1719364ce8bee082f8c4a32804e7b90c9dec887cde4b
Section: utils
Priority: optional
Description: Official Avahi mDNS configuration for Tiny Llama by InsightReactions

Package: tinyllama-ollama
Version: 1.0.8-0.3.10
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: curl
Filename: pool/testing/main/tinyllama-ollama_1.0.8-0.3.10_amd64.deb
Size: 1154
MD5sum: 89df81859ae12229fb499aa10dd85c57
SHA1: abd3a0f45f01dcd6ec6ae81a51e84e812544b221
SHA256: e9784597fcffd46ba6e65da91e470bae0bbc573ebe63cb87e7fde820915406b6
Section: utils
Priority: optional
Description: ollama configured for the Tiny Llama AI Home server platform by InsightReactions
Reccomends: tinyllama

Package: tinyllama-openedai-speech
Version: 1.0.1-0.17.2
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: docker-ce
Recommends: tinyllama
Filename: pool/testing/main/tinyllama-openedai-speech_1.0.1-0.17.2_amd64.deb
Size: 1820
MD5sum: 965708580886229b1b0d212ddc255c43
SHA1: 0619743992aeaab5379f70337c2b56435d5f8b12
SHA256: d4c7f20b4158491e5b9f4300a0fa6dc66a0f21fad45581cdd01b1ebbade288f1
Section: utils
Priority: optional
Description: Open WebUI is an extensible, feature-rich, and user-friendly self-hosted web-based AI
 chat interface designed to operate entirely offline. It supports various LLM runners, including Ollama and
 OpenAI-compatible APIs.

Package: tlweb-amica
Version: 1.0.0-0.2.1
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: sudo, git, nodejs, npm, tinyllama-ollama ( >= 1.0.8-0.3.10 ), tinyllama-openedai-speech
Recommends: tinyllama
Filename: pool/testing/main/tlweb-amica_1.0.0-0.2.1_amd64.deb
Size: 1778
MD5sum: 7c576f8989872d351ef946952e81cbb5
SHA1: b6d1b1f0b2b5c172499c5359273673d4447b75b9
SHA256: 384d676b91bc590c0820cb1a34137d8547e1dbfba2426e5bb9999c569e760029
Section: utils
Priority: optional
Description: Amica is an open source interface for interactive communication with 3D characters with voice synthesis and speech recognition.

Package: tlweb-marketplace
Version: 1.0.3
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Filename: pool/testing/main/tlweb-marketplace_1.0.3_amd64.deb
Size: 27642
MD5sum: dfdb641f9b6e64b3106aafbc3d61fb46
SHA1: 20ce26ef551ebb7647efbb9726c95d5f0da2f974
SHA256: b92ce3b67297904051141c10b57110491da5ed049b0b00b2ae64dcf120d89a1a
Section: utils
Priority: optional
Description: The Official Tiny Llama Marketplace by InsightReactions

Package: tlweb-open-webui
Version: 1.3.2-0.3.16
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: docker-ce, tinyllama-ollama ( >= 1.0.8-0.3.10 ), tinyllama-openedai-speech
Recommends: tinyllama
Filename: pool/testing/main/tlweb-open-webui_1.3.2-0.3.16_amd64.deb
Size: 2466
MD5sum: f04ec822e07ee11ca69285614072ec0b
SHA1: e38e517204cd795fcad5f6935891accdceac9a76
SHA256: 6bf9493d1df477cf446db24f7f4f611fc557808233f597be0198b2542dcd2008
Section: utils
Priority: optional
Description: Open WebUI is an extensible, feature-rich, and user-friendly self-hosted web-based AI
 chat interface designed to operate entirely offline. It supports various LLM runners, including Ollama and
 OpenAI-compatible APIs.

Package: tlweb-stable-diffusion-webui
Version: 1.0.2-1.10.0
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: wget, git, python3, python3-venv, libgl1, libglib2.0-0, tlweb-swarmui
Recommends: tinyllama
Filename: pool/testing/main/tlweb-stable-diffusion-webui_1.0.2-1.10.0_amd64.deb
Size: 1428
MD5sum: 31b3a933e584c4bb2f9d779eb43d7c03
SHA1: 316ce1443b27c5f0064dab7f37680cd69f34dcae
SHA256: b3f3b552d4724411426f7c172729474bc845594c041025311484e1d1796d4186
Section: utils
Priority: optional
Description: Stable Diffusion WebUI is a browser interface for Stable Diffusion based on Gradio library, created by Automatic1111

Package: tlweb-swarmui
Version: 1.2.2-0.9.2-Beta
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: git, rsync, wget
Recommends: tinyllama
Filename: pool/testing/main/tlweb-swarmui_1.2.2-0.9.2-Beta_amd64.deb
Size: 8886
MD5sum: 7b6244a2b9bf3cc5fe0c4c51859911a8
SHA1: b883bde3138a612d48e4cf6703fd8ac025d552fa
SHA256: 943fbf8671d028239f502fa32e294c18c698526f8d83aa6209e15a8d581db674
Section: utils
Priority: optional
Description: A Modular Stable Diffusion web-based image generation interface, with an emphasis on
 making AI powertools easily accessible, performant, and extensible.

