Package: tinyllama
Version: 1.2.3
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: python3-venv, python3-pip, curl, git, tlweb-marketplace (>= 0.9.1)
Suggests: tinyllama-mdns
Filename: pool/testing/main/tinyllama_1.2.3_amd64.deb
Size: 1300536
MD5sum: da82d61aa8007af16fb249a222f7af8c
SHA1: 370f6e471ba87ad2b788938238df4cebc49205b3
SHA256: 1c9a37e049906756f3eacdfe642c3f0d51811adf0135e56152d9aabf4f878ff2
Section: utils
Priority: optional
Description: Official Tiny Llama webserver by InsightReactions

Package: tinyllama-mdns
Version: 1.0.1
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: avahi-daemon
Recommends: tinyllama
Filename: pool/testing/main/tinyllama-mdns_1.0.1_amd64.deb
Size: 1106
MD5sum: 473c50f29d762a4b292ecaa2d583505e
SHA1: b3ee7cb7b9609407848c6042b61d9d998d6fc5a2
SHA256: eb5de131bb4bca620cdb1719364ce8bee082f8c4a32804e7b90c9dec887cde4b
Section: utils
Priority: optional
Description: Official Avahi mDNS configuration for Tiny Llama by InsightReactions

Package: tinyllama-ollama
Version: 1.0.8-0.3.12
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: curl
Filename: pool/testing/main/tinyllama-ollama_1.0.8-0.3.12_amd64.deb
Size: 1528
MD5sum: 6f00e5ba20df3fdd6e9bb54434f38c8b
SHA1: 8f05263e28f7827864c5d8fb968c2ddc015cf4a7
SHA256: ce39fb4ebe426f6bbdad1fe310ebe0bf1f2820e679b22e2a68194810c5435da0
Section: utils
Priority: optional
Homepage: https://github.com/ollama/ollama
Description: ollama configured for the Tiny Llama AI Home server platform by InsightReactions
Reccomends: tinyllama

Package: tinyllama-openedai-speech
Version: 1.0.1-0.18.2
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: docker-ce
Recommends: tinyllama
Filename: pool/testing/main/tinyllama-openedai-speech_1.0.1-0.18.2_amd64.deb
Size: 2124
MD5sum: 8f30027481ccf1a69ab6afcc19b7a8a0
SHA1: fc0c7882cd94edca10266e23be2e245b3bf12591
SHA256: f979746efde8db4ffb9e84cd48b43ecdf569287c90f1fafe07d3dd4311ea8193
Section: utils
Priority: optional
Homepage: https://github.com/matatonic/openedai-speech
Description: An OpenAI API compatible text to speech server.

Package: tlweb-amica
Version: 1.0.1-0.2.1
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: sudo, git, nodejs, npm, tinyllama-ollama ( >= 1.0.8-0.3.10 ), tinyllama-openedai-speech
Recommends: tinyllama
Filename: pool/testing/main/tlweb-amica_1.0.1-0.2.1_amd64.deb
Size: 1778
MD5sum: aa127da9d352c5f9ef124ced86f05fd5
SHA1: bbf29b462773ad9cdcc39f3bfc9c13533871fd9b
SHA256: 4c1feb363c634e4a15e64985f80d5a1e1d10a18bbbb5ed93df86c42f94d6500d
Section: utils
Priority: optional
Description: Amica is an open source interface for interactive communication with 3D characters with voice synthesis and speech recognition.

Package: tlweb-langflow
Version: 1.0.0-1.0.18
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: docker-ce, tinyllama-ollama
Recommends: tinyllama
Filename: pool/testing/main/tlweb-langflow_1.0.0-1.0.18_amd64.deb
Size: 2336
MD5sum: 612ab94942763963986ecc6ea85648d0
SHA1: 0d9e5092a58a0c6d73ace102bcfbf8babe15f1a8
SHA256: 23ea7b0c07b9d3071cfc5f21ab2880ab6c580790a5df70f28092f9cc76dc1a26
Section: utils
Priority: optional
Homepage: https://github.com/langflow-ai/langflow
Description: Langflow is a low-code app builder for RAG and multi-agent AI applications.

Package: tlweb-marketplace
Version: 1.0.4
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Filename: pool/testing/main/tlweb-marketplace_1.0.4_amd64.deb
Size: 32516
MD5sum: 40a5980651bec254c3d43cf75d42ba0a
SHA1: 7623d40df5258bb506de0cdabd5d5b35ccfdd571
SHA256: 96d4eee03a07a271db060dbaa80477816dbcddbeb5f7b0d766597dda6f0ae0f3
Section: utils
Priority: optional
Description: The Official Tiny Llama Marketplace by InsightReactions

Package: tlweb-open-webui
Version: 1.3.3-0.3.30
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: docker-ce, tinyllama-ollama ( >= 1.0.8-0.3.10 ), tinyllama-openedai-speech
Recommends: tinyllama
Filename: pool/testing/main/tlweb-open-webui_1.3.3-0.3.30_amd64.deb
Size: 2270
MD5sum: 842645bd3cc6a7b90d7d61df25d1872e
SHA1: 7f8a4c753158024b239a68e6e9a0f01d07bdb5d2
SHA256: 1cdcff1c72169d88d2293b35ee5248cb342631edbbacb8f3606cdc224516bddc
Section: utils
Priority: optional
Homepage: https://github.com/open-webui/open-webui
Description: Open WebUI is an extensible, feature-rich, and user-friendly self-hosted web-based AI
 chat interface designed to operate entirely offline. It supports various LLM runners, including Ollama and
 OpenAI-compatible APIs.

Package: tlweb-stable-diffusion-webui
Version: 1.0.2-1.10.0
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: wget, git, python3, python3-venv, libgl1, libglib2.0-0, tlweb-swarmui
Recommends: tinyllama
Filename: pool/testing/main/tlweb-stable-diffusion-webui_1.0.2-1.10.0_amd64.deb
Size: 1428
MD5sum: 31b3a933e584c4bb2f9d779eb43d7c03
SHA1: 316ce1443b27c5f0064dab7f37680cd69f34dcae
SHA256: b3f3b552d4724411426f7c172729474bc845594c041025311484e1d1796d4186
Section: utils
Priority: optional
Description: Stable Diffusion WebUI is a browser interface for Stable Diffusion based on Gradio library, created by Automatic1111

Package: tlweb-swarmui
Version: 1.2.2-0.9.2-Beta
Architecture: amd64
Maintainer: InsightReactions <support@insightreactions.com>
Depends: git, rsync, wget
Recommends: tinyllama
Filename: pool/testing/main/tlweb-swarmui_1.2.2-0.9.2-Beta_amd64.deb
Size: 8886
MD5sum: 7b6244a2b9bf3cc5fe0c4c51859911a8
SHA1: b883bde3138a612d48e4cf6703fd8ac025d552fa
SHA256: 943fbf8671d028239f502fa32e294c18c698526f8d83aa6209e15a8d581db674
Section: utils
Priority: optional
Description: A Modular Stable Diffusion web-based image generation interface, with an emphasis on
 making AI powertools easily accessible, performant, and extensible.

